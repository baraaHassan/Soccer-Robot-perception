{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d94fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os,gc\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageStat\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "from torch import randperm,unique\n",
    "from torch._utils import _accumulate\n",
    "import torchvision.transforms.functional as F\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from skimage import io, transform\n",
    "import sklearn.metrics as skm\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import manual_seed,zeros_like,zeros,ones,unique,autograd,device,cuda,cat,save,load,tensor,utils,rand\n",
    "from torch import sum as torch_sum\n",
    "manual_seed(17)\n",
    "random.seed(17)\n",
    "###TODO\n",
    "resize_mode = \"\"\n",
    "resize_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187eac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxaliaryFunctions():\n",
    "    \"\"\"Cutomized Dataset used to train the model.\n",
    "    Args:\n",
    "      root_dir: path where all the training files are saved.\n",
    "      transform: transformations to be applied to the dataset.\n",
    "      filenames: names of all the files in training dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def file_extension(file):\n",
    "        if file.endswith(\".jpg\"):\n",
    "          extension = \".jpg\"\n",
    "        elif file.endswith(\".jpeg\"):\n",
    "          extension = \".jpeg\"\n",
    "        elif file.endswith(\".png\") and not file.endswith(\"_heatmap.png\"):\n",
    "          extension = \".png\"\n",
    "        else:\n",
    "          extension = \"null\"\n",
    "        return extension\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_image(root_dir,filename,only_image_transforms):\n",
    "        filepath = os.path.join(root_dir,filename)\n",
    "        img = Image.open(filepath)\n",
    "        \n",
    "        if only_image_transforms:\n",
    "            img = only_image_transforms(img)\n",
    "    \n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_transformers(image,target,target2=None,normalize_transformer=None):\n",
    "\n",
    "        image = F.to_tensor(image)\n",
    "        target = F.to_tensor(target)\n",
    "        if target2:\n",
    "            target2 = F.to_tensor(target2)\n",
    "        \n",
    "        if normalize_transformer:\n",
    "            image = normalize_transformer(image)\n",
    "\n",
    "        return image , target, target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c56118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionDataset(Dataset):\n",
    "    \"\"\"Cutomized Dataset used to train the model.\n",
    "    Args:\n",
    "      root_dir: path where all the training files are saved.\n",
    "      transform: transformations to be applied to the dataset.\n",
    "      filenames: names of all the files in training dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self,root_dir,only_image_transforms=None,normalize_transformer=None):\n",
    "        super(DetectionDataset, self).__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.only_image_transforms = only_image_transforms\n",
    "        self.normalize_transformer = normalize_transformer\n",
    "        #self.filenames, self.heatmap_filenames, self.xml_filenames = data.get_rest_detection()\n",
    "        \n",
    "        self.filenames = []\n",
    "        self.heatmap_filenames = []\n",
    "        self.xml_filenames = []\n",
    "        \n",
    "        ###TODO\n",
    "        #count = 1\n",
    "        \n",
    "        for subfolder in [\"dataset\",\"forceTrain\",\"forceTest\"]:\n",
    "            root_dir2 = os.path.join(root_dir,subfolder)\n",
    "            for file in os.listdir(root_dir2):\n",
    "                ###TODO\n",
    "#                 if count > 32:\n",
    "#                     break\n",
    "                extension = AuxaliaryFunctions.file_extension(file)\n",
    "\n",
    "                if extension == \"null\":\n",
    "                    continue\n",
    "                    \n",
    "                #print(\"sks \", os.path.join(subfolder,file))\n",
    "                self.filenames.append(os.path.join(subfolder,file))\n",
    "                self.heatmap_filenames.append(os.path.join(subfolder,file.replace(extension,\"_heatmap.png\")))\n",
    "                self.xml_filenames.append(os.path.join(subfolder,file.replace(extension,'.xml')))\n",
    "                ###TODO\n",
    "                #count += 1\n",
    "                \n",
    "    def __len__(self):\n",
    "        \"\"\"Length of the dataset\"\"\"\n",
    "        return len(self.heatmap_filenames)\n",
    "    \n",
    "    def set_transformers(self,normalize_transformer,only_image_transforms):\n",
    "        self.normalize_transformer = normalize_transformer\n",
    "        self.only_image_transforms = only_image_transforms\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        #print(self.root_dir)\n",
    "        img = AuxaliaryFunctions.get_image(self.root_dir,self.filenames[ind],self.only_image_transforms)\n",
    "        heatmap = Image.open(os.path.join(self.root_dir,self.heatmap_filenames[ind]))\n",
    "        img,heatmap,_ = AuxaliaryFunctions.apply_transformers(img,heatmap,normalize_transformer=self.normalize_transformer)\n",
    "#         if heatmap.max() > 1:\n",
    "#             print(\"eiiiiiiiiiiiiiiiiiiiiih??\",heatmap.max())\n",
    "        #print(heatmap[0,0])\n",
    "        #print(heatmap[0,50])\n",
    "        #print(heatmap[0,100])\n",
    "        #heatmap[heatmap == 0] = 0.1\n",
    "        \n",
    "        ###TODO\n",
    "        #heat = zeros_like(heatmap)\n",
    "        #heat[heatmap==0] = 1\n",
    "        #heat[heatmap==1] = 0\n",
    "        \n",
    "        ###TODO\n",
    "        return img, heatmap\n",
    "        #return {'input':img, 'heatmap': heat}\n",
    "    \n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self,root_dir,only_image_transforms=None,normalize_transformer=None):\n",
    "        super(SegmentationDataset, self).__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.only_image_transforms = only_image_transforms\n",
    "        self.normalize_transformer = normalize_transformer\n",
    "        #self.filenames, self.target_filenames = data.get_rest_segmentation()\n",
    "        self.filenames = []\n",
    "        self.target_filenames = []\n",
    "        \n",
    "        ###TODO\n",
    "#         count = 1\n",
    "        \n",
    "        for subfolder in [\"dataset\",\"forceTrain\"]:\n",
    "            root_dir2 = os.path.join(root_dir,subfolder,\"image\")\n",
    "\n",
    "            for file in os.listdir(root_dir2):\n",
    "               ###TODO \n",
    "#                 if count > 32:\n",
    "#                     break\n",
    "                \n",
    "                extension = AuxaliaryFunctions.file_extension(file)\n",
    "\n",
    "                if extension == \"null\":\n",
    "                    continue\n",
    "\n",
    "                self.filenames.append(os.path.join(subfolder,\"image\",file))\n",
    "                self.target_filenames.append(os.path.join(subfolder,\"target\",file.replace(extension,\".png\")))\n",
    "                ###TODO\n",
    "#                 count += 1\n",
    "    def __getitem__(self, ind):\n",
    "            img = AuxaliaryFunctions.get_image(self.root_dir,self.filenames[ind],self.only_image_transforms)\n",
    "            label = cv2.imread(os.path.join(self.root_dir,self.target_filenames[ind]),0)\n",
    "            label = Image.fromarray(np.uint8(label))\n",
    "            img,label,_ = AuxaliaryFunctions.apply_transformers(img,label,normalize_transformer = self.normalize_transformer)\n",
    "            \n",
    "            label[(1 == label)] = 2\n",
    "            label[((0 < label) & (1 > label))] = 1\n",
    "            label = label.squeeze()\n",
    "            \n",
    "            return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def set_transformers(self,normalize_transformer,only_image_transforms):\n",
    "        self.normalize_transformer = normalize_transformer\n",
    "        self.only_image_transforms = only_image_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d8d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57286466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
