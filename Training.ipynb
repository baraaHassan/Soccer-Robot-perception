{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab729499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2cf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Custom_Dataset.ipynb\n",
    "%run Nibronet2_Model.ipynb\n",
    "%run Extra_Utilities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blessed-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os,gc\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageStat\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "from torch import randperm,unique\n",
    "from torch._utils import _accumulate\n",
    "import torchvision.transforms.functional as F\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from skimage import io, transform\n",
    "import sklearn.metrics as skm\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import manual_seed,zeros_like,zeros,ones,unique,autograd,device,cuda,cat,save,load,tensor,utils,rand\n",
    "from torch import sum as torch_sum\n",
    "manual_seed(17)\n",
    "random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nominated-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Detection:  7086  samples for training  887  samples for validation  885  samlpes for testing\n"
     ]
    }
   ],
   "source": [
    "                                 ##### Detection Datasets & Dataloaders #####\n",
    "\n",
    "# Data Augmentation\n",
    "only_image_transforms = transforms.Compose([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5)])#,transforms.RandomGrayscale(p=0.3)])\n",
    "                \n",
    "##### Detection Dataset ####\n",
    "\n",
    "# batchsize for detection\n",
    "batch_size_detection = 32\n",
    "\n",
    "# The whole dataset for detection\n",
    "dataset_detection = DetectionDataset(\"/home/user/bhassan/baraa/dataset/data/blob\",only_image_transforms,transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]))\n",
    "\n",
    "\n",
    "### spliting the dataset into 80% for training and 10% validation and 10% testing ###\n",
    "len_dataset_detection = len(dataset_detection)\n",
    "len_train_dataset_detection,len_test_dataset_detection = int(len_dataset_detection * 0.8),int(0.1*len_dataset_detection)\n",
    "len_valid_dataset_detection = len_dataset_detection - (len_train_dataset_detection + len_test_dataset_detection)\n",
    "\n",
    "## splitting datasets ###\n",
    "train_dataset_detection, validation_dataset_detection, test_dataset_detection = utils.data.random_split(dataset_detection,[len_train_dataset_detection, len_valid_dataset_detection, len_test_dataset_detection])\n",
    "\n",
    "### dataloaders for detection ###\n",
    "train_loader_detection = utils.data.DataLoader(dataset=train_dataset_detection, \n",
    "                                           batch_size=batch_size_detection, \n",
    "                                           shuffle=True)#,**kwargs)\n",
    "val_loader_detection = utils.data.DataLoader(dataset=validation_dataset_detection, \n",
    "                                           batch_size=batch_size_detection, \n",
    "                                           shuffle=True)#,**kwargs)\n",
    "test_loader_detection = utils.data.DataLoader(dataset=test_dataset_detection, \n",
    "                                           batch_size=batch_size_detection, \n",
    "                                           shuffle=True)#,**kwargs)\n",
    "\n",
    "print(\"for Detection: \", len_train_dataset_detection, \" samples for training \", len_valid_dataset_detection, \" samples for validation \", len_test_dataset_detection, \" samlpes for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4eed89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Segmentation:  953  samples for training  120  samples for validation  119  samlpes for testing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                                ##### Segmentation Datasets & Dataloaders #####\n",
    "\n",
    "#### segmentation dataset #####\n",
    "\n",
    "# batch size for segmentation\n",
    "batch_size_segmentation = 32\n",
    "\n",
    "# The whole dataset for segmentation\n",
    "dataset_segmentation = SegmentationDataset(\"/home/user/bhassan/baraa/dataset/data/segmentation\",only_image_transforms,transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]))\n",
    "\n",
    "\n",
    "### spliting the dataset into 80% for training and 10% validation and 10% testing ###\n",
    "\n",
    "len_dataset_segmentation = len(dataset_segmentation)\n",
    "len_train_dataset_segmentation,len_test_dataset_segmentation = int(len_dataset_segmentation * 0.8),int(0.1*len_dataset_segmentation)\n",
    "len_valid_dataset_segmentation = len_dataset_segmentation - (len_train_dataset_segmentation + len_test_dataset_segmentation)\n",
    "\n",
    "\n",
    "# # splitting datasets\n",
    "train_dataset_segmentation, validation_dataset_segmentation, test_dataset_segmentation = utils.data.random_split(dataset_segmentation,[len_train_dataset_segmentation,len_valid_dataset_segmentation,len_test_dataset_segmentation])\n",
    "\n",
    "### dataloaders ###\n",
    "train_loader_segmentation = utils.data.DataLoader(dataset=train_dataset_segmentation, \n",
    "                                           batch_size=batch_size_segmentation, \n",
    "                                           shuffle=True)#,**kwargs)\n",
    "val_loader_segmentation = utils.data.DataLoader(dataset=validation_dataset_segmentation, \n",
    "                                           batch_size=batch_size_segmentation, \n",
    "                                           shuffle=True)#,**kwargs)\n",
    "test_loader_segmentation = utils.data.DataLoader(dataset=test_dataset_segmentation, \n",
    "                                           batch_size=batch_size_segmentation, \n",
    "                                           shuffle=True)#,**kwargs)\n",
    "\n",
    "print(\"for Segmentation: \", len_train_dataset_segmentation, \" samples for training \", len_valid_dataset_segmentation, \" samples for validation \", len_test_dataset_segmentation, \" samlpes for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "functioning-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "current_device = device(\"cuda:0\" if cuda.is_available() else \"cpu\")\n",
    "print(current_device)\n",
    "model = NimbroNet2()\n",
    "model.to(current_device)\n",
    "\n",
    "# Criterion for Segmentation\n",
    "criterion_s = nn.CrossEntropyLoss()#(weight=tensor([0.15,0.15,0.7]).to(current_device))\n",
    "criterion_s.to(current_device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.01,step_size_up = 20000,cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88cf5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(loss_d_vector,loss_s_vector,iterations,epochs,init_epoch):\n",
    "    for epoch in range(init_epoch, epochs+1):\n",
    "        print(\"epoch\",epoch)\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # batch detection\n",
    "            images_det,heatmaps = next(iter(train_loader_detection))\n",
    "            images_det = images_det.to(current_device)\n",
    "            heatmaps = heatmaps.to(current_device)\n",
    "            \n",
    "            # batch segmentation\n",
    "            images_seg,target = next(iter(train_loader_segmentation))\n",
    "            images_seg = images_seg.to(current_device)\n",
    "            target = target.to(current_device)\n",
    "\n",
    "            # To save memory from exceeding limit\n",
    "            gc.collect()\n",
    "            cuda.empty_cache()\n",
    "            cuda.reset_max_memory_allocated()\n",
    "\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with cuda.amp.autocast():\n",
    "                # Forward pass to get detection output\n",
    "                _,outputsD = model(images_det)\n",
    "                \n",
    "                # Forward pass to get segmentation output\n",
    "                outputsS,_ = model(images_seg)\n",
    "                \n",
    "                ### Calculate Loss ###\n",
    "                \n",
    "                # Loss of detection\n",
    "                loss_d = mse_loss_fn(outputsD.float(), heatmaps)\n",
    "                \n",
    "                # Loss of segmentation\n",
    "                loss_s =  (criterion_s(outputsS, target.long()))\n",
    "                \n",
    "                # Total loss\n",
    "                loss = 0.03 * loss_d + loss_s + tv_loss(outputsD,4e-5,[0,1,2]) + tv_loss(outputsS,1e-7,[0,1])\n",
    "                \n",
    "\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            # chaning the learning rate of the cyclic learning rate\n",
    "            scheduler.step()\n",
    "        \n",
    "\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} Loss segmentation:{:.6f} Loss detection {:.6f}'.format(\n",
    "            epoch, iteration * len(images_det), len(train_loader_detection.dataset),\n",
    "            100. * float(iteration) / len(train_loader_detection), loss.item(),loss_s.item(),loss_d.item()))\n",
    "        loss_d_vector.append(loss_d.item())\n",
    "        loss_s_vector.append(loss_s.item())\n",
    "\n",
    "    # showing the output after training for one epoch        \n",
    "#         outputsS,outputsD = model(images_det)\n",
    "#         outputsD =outputsD[0]\n",
    "\n",
    "\n",
    "#         plt.imshow(trans(heatmaps[0].cpu()))\n",
    "#         plt.show()\n",
    "\n",
    "#         target = target[0]\n",
    "#         target[target == 0] = 0\n",
    "#         target[target == 2] = 255 \n",
    "#         target[target == 1] = 128\n",
    "\n",
    "#         plt.imshow(target.cpu(), cmap='gray', vmin=0, vmax=255,interpolation='nearest')\n",
    "#         plt.show()\n",
    "\n",
    "#         img = outputsS.data.max(1)[1]        \n",
    "#         img[img == 0] = 0\n",
    "#         img[img == 2] = 255 \n",
    "#         img[img == 1] = 128\n",
    "#         plt.imshow(img[0].cpu(), cmap='gray', vmin=0, vmax=255,interpolation='nearest')\n",
    "#         plt.show()\n",
    "\n",
    "#         print(outputsD.max())\n",
    "#         print(outputsD.min())\n",
    "\n",
    "#         outputsD[outputsD<0] = 0\n",
    "#         outputsD[outputsD>1] = 1\n",
    "#         plt.imshow(trans(outputsD.cpu()))\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#         inp = images_det[0].cpu()\n",
    "#         inp = inp.numpy().transpose((1, 2, 0))\n",
    "#         #mean = np.array([0.3539, 0.3919, 0.2552])\n",
    "#         #std = np.array([0.0391, 0.0384, 0.0438])\n",
    "#         mean = np.array(det_mean)\n",
    "#         std = np.array(det_std)\n",
    "#         inp = std * inp + mean\n",
    "#         inp = np.clip(inp, 0, 1)\n",
    "#         inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "#         plt.imshow(inp)\n",
    "#         plt.show()\n",
    "        #plt.imshow(transforms.ToPILImage()(images[0].cpu()))\n",
    "        #plt.show()\n",
    "        \n",
    "        if (epoch % 5 == 0):\n",
    "           path = \"/home/user/bhassan/baraa/total_loss_full_batch_epoch\" + str(epoch) + \".th\"\n",
    "           save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss_d':loss_d_vector,\n",
    "                'loss_s':loss_s_vector,\n",
    "                'DetectionTrainDataLoader': train_loader_detection,\n",
    "                'SegmentationTrainDataLoader': train_loader_segmentation,\n",
    "                'DetectionTestDataLoader': test_loader_detection,\n",
    "                'DetectionValidationDataLoader': val_loader_detection,\n",
    "                'SegmentationTestDataLoader': test_loader_segmentation,\n",
    "                'SegmentationValidationDataLoader': val_loader_segmentation\n",
    "                }, path)\n",
    "\n",
    "        print(\"lr = \",optimizer.state_dict()[\"param_groups\"][0][\"lr\"])\n",
    "    return loss_d_vector,loss_s_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1878040",
   "metadata": {},
   "outputs": [],
   "source": [
    "freezing(model.resnet_encoder_block1.parameters(),False)\n",
    "freezing(model.resnet_encoder_block2.parameters(),False)\n",
    "freezing(model.resnet_encoder_block3.parameters(),False)\n",
    "freezing(model.resnet_encoder_block4.parameters(),False)\n",
    "loss_d_vector,loss_s_vector = [],[]\n",
    "loss_d_vector,loss_s_vector = train_model(loss_d_vector,loss_s_vector,200,50,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42b9cc",
   "metadata": {},
   "source": [
    "# There was a connection problem in the server so I had to repeat the training from epoch 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92427ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41\n",
      "Train Epoch: 41 [6368/7086 (90%)]\tLoss: 0.288695 Loss segmentation:0.043272 Loss detection 7.874002\n",
      "lr =  0.001991799999999999\n",
      "epoch 42\n",
      "Train Epoch: 42 [6368/7086 (90%)]\tLoss: 0.258599 Loss segmentation:0.048363 Loss detection 6.725509\n",
      "lr =  0.002081800000000001\n",
      "epoch 43\n",
      "Train Epoch: 43 [6368/7086 (90%)]\tLoss: 0.765309 Loss segmentation:0.436301 Loss detection 10.603941\n",
      "lr =  0.002171799999999999\n",
      "epoch 44\n",
      "Train Epoch: 44 [6368/7086 (90%)]\tLoss: 0.589177 Loss segmentation:0.223264 Loss detection 11.805671\n",
      "lr =  0.0022618000000000013\n",
      "epoch 45\n",
      "Train Epoch: 45 [6368/7086 (90%)]\tLoss: 0.483413 Loss segmentation:0.166763 Loss detection 10.201948\n",
      "lr =  0.0023517999999999994\n",
      "epoch 46\n",
      "Train Epoch: 46 [6368/7086 (90%)]\tLoss: 0.431735 Loss segmentation:0.129757 Loss detection 9.772356\n",
      "lr =  0.0024418000000000013\n",
      "epoch 47\n",
      "Train Epoch: 47 [6368/7086 (90%)]\tLoss: 0.425974 Loss segmentation:0.111419 Loss detection 10.182708\n",
      "lr =  0.0025317999999999994\n",
      "epoch 48\n",
      "Train Epoch: 48 [6368/7086 (90%)]\tLoss: 0.397496 Loss segmentation:0.122040 Loss detection 8.906840\n",
      "lr =  0.0026218000000000014\n",
      "epoch 49\n",
      "Train Epoch: 49 [6368/7086 (90%)]\tLoss: 0.362284 Loss segmentation:0.084917 Loss detection 8.939561\n",
      "lr =  0.0027117999999999995\n",
      "epoch 50\n",
      "Train Epoch: 50 [6368/7086 (90%)]\tLoss: 0.362181 Loss segmentation:0.089610 Loss detection 8.797954\n",
      "lr =  0.002801800000000002\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/user/bhassan/baraa/total_loss_full_batch_epoch40.th\"\n",
    "checkpoint = load(path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch_init = checkpoint['epoch']\n",
    "test_loader_detection = checkpoint['DetectionTestDataLoader']\n",
    "val_loader_detection = checkpoint['DetectionValidationDataLoader']\n",
    "test_loader_segmentation = checkpoint['SegmentationTestDataLoader']\n",
    "val_loader_segmentation = checkpoint['SegmentationValidationDataLoader']\n",
    "train_loader_detection = checkpoint['DetectionTrainDataLoader']\n",
    "train_loader_segmentation = checkpoint['SegmentationTrainDataLoader']\n",
    "loss_d_vector = checkpoint['loss_d']\n",
    "loss_s_vector = checkpoint['loss_s']\n",
    "#print(epoch_init)\n",
    "loss_d_vector,loss_s_vector = train_model(loss_d_vector,loss_s_vector,200,50,epoch_init+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14cfb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51\n",
      "Train Epoch: 51 [6368/7086 (90%)]\tLoss: 0.345014 Loss segmentation:0.066339 Loss detection 9.010564\n",
      "lr =  0.0028918\n",
      "epoch 52\n",
      "Train Epoch: 52 [6368/7086 (90%)]\tLoss: 0.342296 Loss segmentation:0.066385 Loss detection 8.921173\n",
      "lr =  0.002981800000000002\n",
      "epoch 53\n",
      "Train Epoch: 53 [6368/7086 (90%)]\tLoss: 0.364717 Loss segmentation:0.092232 Loss detection 8.800212\n",
      "lr =  0.0030718\n",
      "epoch 54\n",
      "Train Epoch: 54 [6368/7086 (90%)]\tLoss: 0.346673 Loss segmentation:0.073410 Loss detection 8.767645\n",
      "lr =  0.003161800000000002\n",
      "epoch 55\n",
      "Train Epoch: 55 [6368/7086 (90%)]\tLoss: 0.345793 Loss segmentation:0.062654 Loss detection 9.141215\n",
      "lr =  0.0032518\n",
      "epoch 56\n",
      "Train Epoch: 56 [6368/7086 (90%)]\tLoss: 0.348243 Loss segmentation:0.077004 Loss detection 8.755787\n",
      "lr =  0.003341800000000002\n",
      "epoch 57\n",
      "Train Epoch: 57 [6368/7086 (90%)]\tLoss: 0.418540 Loss segmentation:0.072962 Loss detection 11.200232\n",
      "lr =  0.0034318000000000005\n",
      "epoch 58\n",
      "Train Epoch: 58 [6368/7086 (90%)]\tLoss: 0.334825 Loss segmentation:0.096466 Loss detection 7.662577\n",
      "lr =  0.0035217999999999985\n",
      "epoch 59\n",
      "Train Epoch: 59 [6368/7086 (90%)]\tLoss: 0.332779 Loss segmentation:0.083336 Loss detection 8.005337\n",
      "lr =  0.0036118000000000005\n",
      "epoch 60\n",
      "Train Epoch: 60 [6368/7086 (90%)]\tLoss: 0.359373 Loss segmentation:0.049259 Loss detection 10.043350\n",
      "lr =  0.0037018000000000025\n",
      "epoch 61\n",
      "Train Epoch: 61 [6368/7086 (90%)]\tLoss: 0.323120 Loss segmentation:0.064240 Loss detection 8.339082\n",
      "lr =  0.0037918000000000006\n",
      "epoch 62\n",
      "Train Epoch: 62 [6368/7086 (90%)]\tLoss: 0.379937 Loss segmentation:0.084734 Loss detection 9.543409\n",
      "lr =  0.0038817999999999986\n",
      "epoch 63\n",
      "Train Epoch: 63 [6368/7086 (90%)]\tLoss: 0.309474 Loss segmentation:0.069502 Loss detection 7.731853\n",
      "lr =  0.003971800000000001\n",
      "epoch 64\n",
      "Train Epoch: 64 [6368/7086 (90%)]\tLoss: 0.366110 Loss segmentation:0.080715 Loss detection 9.193449\n",
      "lr =  0.004061799999999999\n",
      "epoch 65\n",
      "Train Epoch: 65 [6368/7086 (90%)]\tLoss: 0.307606 Loss segmentation:0.073572 Loss detection 7.471315\n",
      "lr =  0.004151800000000001\n",
      "epoch 66\n",
      "Train Epoch: 66 [6368/7086 (90%)]\tLoss: 0.304199 Loss segmentation:0.063933 Loss detection 7.752313\n",
      "lr =  0.004241799999999999\n",
      "epoch 67\n",
      "Train Epoch: 67 [6368/7086 (90%)]\tLoss: 0.318893 Loss segmentation:0.066502 Loss detection 8.113646\n",
      "lr =  0.004331800000000001\n",
      "epoch 68\n",
      "Train Epoch: 68 [6368/7086 (90%)]\tLoss: 0.322442 Loss segmentation:0.058842 Loss detection 8.488481\n",
      "lr =  0.004421799999999999\n",
      "epoch 69\n",
      "Train Epoch: 69 [6368/7086 (90%)]\tLoss: 0.247674 Loss segmentation:0.047592 Loss detection 6.372003\n",
      "lr =  0.004511800000000002\n",
      "epoch 70\n",
      "Train Epoch: 70 [6368/7086 (90%)]\tLoss: 0.318879 Loss segmentation:0.055966 Loss detection 8.477903\n",
      "lr =  0.0046018\n",
      "epoch 71\n",
      "Train Epoch: 71 [6368/7086 (90%)]\tLoss: 0.300746 Loss segmentation:0.058383 Loss detection 7.827840\n",
      "lr =  0.004691800000000001\n",
      "epoch 72\n",
      "Train Epoch: 72 [6368/7086 (90%)]\tLoss: 0.367846 Loss segmentation:0.088913 Loss detection 8.984335\n",
      "lr =  0.004781799999999999\n",
      "epoch 73\n",
      "Train Epoch: 73 [6368/7086 (90%)]\tLoss: 0.292001 Loss segmentation:0.064471 Loss detection 7.306654\n",
      "lr =  0.004871800000000002\n",
      "epoch 74\n",
      "Train Epoch: 74 [6368/7086 (90%)]\tLoss: 0.302679 Loss segmentation:0.053414 Loss detection 8.020802\n",
      "lr =  0.0049618\n",
      "epoch 75\n",
      "Train Epoch: 75 [6368/7086 (90%)]\tLoss: 0.269803 Loss segmentation:0.062259 Loss detection 6.638034\n",
      "lr =  0.005051800000000002\n",
      "epoch 76\n",
      "Train Epoch: 76 [6368/7086 (90%)]\tLoss: 0.290627 Loss segmentation:0.066137 Loss detection 7.181146\n",
      "lr =  0.0051418\n",
      "epoch 77\n",
      "Train Epoch: 77 [6368/7086 (90%)]\tLoss: 0.302859 Loss segmentation:0.060885 Loss detection 7.776824\n",
      "lr =  0.005231800000000002\n",
      "epoch 78\n",
      "Train Epoch: 78 [6368/7086 (90%)]\tLoss: 0.273904 Loss segmentation:0.057747 Loss detection 6.944432\n",
      "lr =  0.0053218\n",
      "epoch 79\n",
      "Train Epoch: 79 [6368/7086 (90%)]\tLoss: 0.309361 Loss segmentation:0.066207 Loss detection 7.847748\n",
      "lr =  0.005411800000000002\n",
      "epoch 80\n",
      "Train Epoch: 80 [6368/7086 (90%)]\tLoss: 0.274504 Loss segmentation:0.053575 Loss detection 7.100567\n",
      "lr =  0.0055018\n",
      "epoch 81\n",
      "Train Epoch: 81 [6368/7086 (90%)]\tLoss: 0.321866 Loss segmentation:0.067721 Loss detection 8.192280\n",
      "lr =  0.005591800000000003\n",
      "epoch 82\n",
      "Train Epoch: 82 [6368/7086 (90%)]\tLoss: 0.320525 Loss segmentation:0.056734 Loss detection 8.210021\n",
      "lr =  0.005681800000000001\n",
      "epoch 83\n",
      "Train Epoch: 83 [6368/7086 (90%)]\tLoss: 0.454277 Loss segmentation:0.141575 Loss detection 10.203446\n",
      "lr =  0.005771799999999999\n",
      "epoch 84\n",
      "Train Epoch: 84 [6368/7086 (90%)]\tLoss: 0.385150 Loss segmentation:0.130608 Loss detection 8.278680\n",
      "lr =  0.0058618\n",
      "epoch 85\n",
      "Train Epoch: 85 [6368/7086 (90%)]\tLoss: 0.367263 Loss segmentation:0.094767 Loss detection 8.840881\n",
      "lr =  0.005951800000000003\n",
      "epoch 86\n",
      "Train Epoch: 86 [6368/7086 (90%)]\tLoss: 0.347132 Loss segmentation:0.077189 Loss detection 8.760183\n",
      "lr =  0.006041800000000001\n",
      "epoch 87\n",
      "Train Epoch: 87 [6368/7086 (90%)]\tLoss: 0.342451 Loss segmentation:0.071734 Loss detection 8.771110\n",
      "lr =  0.006131799999999999\n",
      "epoch 88\n",
      "Train Epoch: 88 [6368/7086 (90%)]\tLoss: 0.350862 Loss segmentation:0.070185 Loss detection 9.098422\n",
      "lr =  0.006221800000000001\n",
      "epoch 89\n",
      "Train Epoch: 89 [6368/7086 (90%)]\tLoss: 0.364765 Loss segmentation:0.097754 Loss detection 8.627431\n",
      "lr =  0.006311799999999999\n",
      "epoch 90\n"
     ]
    }
   ],
   "source": [
    "freezing(model.resnet_encoder_block1.parameters(),True)\n",
    "freezing(model.resnet_encoder_block2.parameters(),True)\n",
    "freezing(model.resnet_encoder_block3.parameters(),True)\n",
    "freezing(model.resnet_encoder_block4.parameters(),True)\n",
    "loss_d_vector,loss_s_vector = train_model(loss_d_vector,loss_s_vector,200,150,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/bhassan/venv/lib/python3.8/site-packages/torch/cuda/memory.py:271: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 86 [6368/7086 (90%)]\tLoss: 0.307919 Loss segmentation:0.062854 Loss detection 7.931314\n",
      "lr =  0.001089999999999998\n",
      "epoch 87\n",
      "Train Epoch: 87 [6368/7086 (90%)]\tLoss: 0.289582 Loss segmentation:0.070931 Loss detection 7.047453\n",
      "lr =  0.0011800000000000003\n",
      "epoch 88\n",
      "Train Epoch: 88 [6368/7086 (90%)]\tLoss: 0.313120 Loss segmentation:0.062137 Loss detection 8.125912\n",
      "lr =  0.0012699999999999983\n",
      "epoch 89\n",
      "Train Epoch: 89 [6368/7086 (90%)]\tLoss: 0.293712 Loss segmentation:0.057587 Loss detection 7.623602\n",
      "lr =  0.0013600000000000003\n",
      "epoch 90\n",
      "Train Epoch: 90 [6368/7086 (90%)]\tLoss: 0.336843 Loss segmentation:0.070767 Loss detection 8.606990\n",
      "lr =  0.0014499999999999986\n",
      "epoch 91\n",
      "Train Epoch: 91 [6368/7086 (90%)]\tLoss: 0.268974 Loss segmentation:0.057177 Loss detection 6.801995\n",
      "lr =  0.0015400000000000006\n",
      "epoch 92\n",
      "Train Epoch: 92 [6368/7086 (90%)]\tLoss: 0.285302 Loss segmentation:0.062081 Loss detection 7.192020\n",
      "lr =  0.0016299999999999986\n",
      "epoch 93\n",
      "Train Epoch: 93 [6368/7086 (90%)]\tLoss: 0.292805 Loss segmentation:0.060784 Loss detection 7.479804\n",
      "lr =  0.0017200000000000006\n",
      "epoch 94\n",
      "Train Epoch: 94 [6368/7086 (90%)]\tLoss: 0.290121 Loss segmentation:0.061210 Loss detection 7.374229\n",
      "lr =  0.0018099999999999987\n",
      "epoch 95\n",
      "Train Epoch: 95 [6368/7086 (90%)]\tLoss: 0.265938 Loss segmentation:0.046631 Loss detection 7.058959\n",
      "lr =  0.001900000000000001\n",
      "epoch 96\n",
      "Train Epoch: 96 [6368/7086 (90%)]\tLoss: 0.295678 Loss segmentation:0.049747 Loss detection 7.926783\n",
      "lr =  0.0019899999999999987\n",
      "epoch 97\n",
      "Train Epoch: 97 [6368/7086 (90%)]\tLoss: 0.319328 Loss segmentation:0.059003 Loss detection 8.398701\n",
      "lr =  0.002080000000000001\n",
      "epoch 98\n",
      "Train Epoch: 98 [6368/7086 (90%)]\tLoss: 0.308050 Loss segmentation:0.065100 Loss detection 7.823740\n",
      "lr =  0.002169999999999999\n",
      "epoch 99\n",
      "Train Epoch: 99 [6368/7086 (90%)]\tLoss: 0.281897 Loss segmentation:0.049875 Loss detection 7.463468\n",
      "lr =  0.0022600000000000016\n",
      "epoch 100\n",
      "Train Epoch: 100 [6368/7086 (90%)]\tLoss: 0.293802 Loss segmentation:0.061118 Loss detection 7.412402\n",
      "lr =  0.0023499999999999997\n",
      "epoch 101\n",
      "Train Epoch: 101 [6368/7086 (90%)]\tLoss: 0.314940 Loss segmentation:0.065711 Loss detection 8.015297\n",
      "lr =  0.002440000000000001\n",
      "epoch 102\n",
      "Train Epoch: 102 [6368/7086 (90%)]\tLoss: 0.256699 Loss segmentation:0.069423 Loss detection 5.982717\n",
      "lr =  0.0025299999999999993\n",
      "epoch 103\n",
      "Train Epoch: 103 [6368/7086 (90%)]\tLoss: 0.293061 Loss segmentation:0.055229 Loss detection 7.643286\n",
      "lr =  0.0026200000000000017\n",
      "epoch 104\n",
      "Train Epoch: 104 [6368/7086 (90%)]\tLoss: 0.287138 Loss segmentation:0.051022 Loss detection 7.596471\n",
      "lr =  0.0027099999999999997\n",
      "epoch 105\n",
      "Train Epoch: 105 [6368/7086 (90%)]\tLoss: 0.290529 Loss segmentation:0.056240 Loss detection 7.539254\n",
      "lr =  0.002800000000000002\n",
      "epoch 106\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/user/bhassan/baraa/total_loss_full_batch_epoch85.th\"\n",
    "checkpoint = load(path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch_init = checkpoint['epoch']\n",
    "test_loader_detection = checkpoint['DetectionTestDataLoader']\n",
    "val_loader_detection = checkpoint['DetectionValidationDataLoader']\n",
    "test_loader_segmentation = checkpoint['SegmentationTestDataLoader']\n",
    "val_loader_segmentation = checkpoint['SegmentationValidationDataLoader']\n",
    "train_loader_detection = checkpoint['DetectionTrainDataLoader']\n",
    "train_loader_segmentation = checkpoint['SegmentationTrainDataLoader']\n",
    "loss_d_vector = checkpoint['loss_d']\n",
    "loss_s_vector = checkpoint['loss_s']\n",
    "#print(epoch_init)\n",
    "loss_d_vector,loss_s_vector = train_model(loss_d_vector,loss_s_vector,200,200,epoch_init+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49ed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
